{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Our task for today will be to classify emails as spam or not spam. We sill use the Enron Email Dataset. The dataset contains email text along with a label of whether that text was spam or not.\n",
    "\n",
    "First, let's load the dataset, and look at an example too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[\n",
    "\\newcommand{\\card}[1]{\\left\\lvert#1\\right\\rvert}\n",
    "\\newcommand{\\condbar}[0]{\\,\\big|\\,}\n",
    "\\newcommand{\\eprob}[1]{\\widehat{\\text{Pr}}\\left[#1\\right]}\n",
    "\\newcommand{\\norm}[1]{\\left\\lvert\\left\\lvert#1\\right\\rvert\\right\\rvert}\n",
    "\\newcommand{\\prob}[1]{\\text{Pr}\\left[#1\\right]}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarfile already downloaded!\n",
      "Tarfile already extracted!\n",
      "Dataset already processed!\n",
      "\n",
      ">>> HAM EMAIL:\n",
      "========================================================================\n",
      "Subject: mcmullen gas for 11 / 99\n",
      "jackie ,\n",
      "since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day of\n",
      "flow ) :\n",
      "at what meter is the mcmullen gas being diverted to ?\n",
      "at what meter is hpl buying the residue gas ? ( this is the gas from teco ,\n",
      "vastar , vintage , tejones , and swift )\n",
      "i still see active deals at meter 3405 in path manager for teco , vastar ,\n",
      "vintage , tejones , and swift\n",
      "i also see gas scheduled in pops at meter 3404 and 3405 .\n",
      "please advice . we need to resolve this as soon as possible so settlement\n",
      "can send out payments .\n",
      "thanks\n",
      "\n",
      ">>> SPAM EMAIL:\n",
      "========================================================================\n",
      "Subject: re : rdd , the auxiliary iturean\n",
      "free cable @ tv\n",
      "dabble bam servomechanism ferret canopy bookcase befog seductive elapse ballard daphne acrylate deride decadent desolate else sequestration condition ligament ornately yaqui giblet emphysematous woodland lie segovia almighty coffey shut china clubroom diagnostician\n",
      "cheer leadsman abominate cambric oligarchy mania woodyard quake tetrachloride contiguous welsh depressive synaptic trauma cloister banks canadian byroad alexander gnaw annette charlie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import lib.download\n",
    "lib.download.run()\n",
    "\n",
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "print()\n",
    "print(\">>> HAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(RAW_DATASET.ham_emails[5].text_content())\n",
    "\n",
    "print()\n",
    "print(\">>> SPAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(RAW_DATASET.spam_emails[10].text_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the email text is all lower case, and each *token* (words, but also symbols like \"@\") is seperated by a space. The subject line is not technically part of the email body, but I will leave it in anyway.\n",
    "\n",
    "For the purposes of our algorithm, we will convert emails into a set of words, throwing away the order of the words, and also how frequently they occur in the email. Every token will be represented with an integer, rather than the word itself.\n",
    "\n",
    "We will represent whether an email is spam or not with a 1 for spam and a 0 for not spam. This is called the *label*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SortedSet([0, 7, 13, 27, 69, 209, 306, 679, 1076, 1466, 1492, 3200, 3498, 3880, 4518, 5332, 5673, 6040, 6075, 7845, 10796, 11378, 11981, 12835, 14532, 16407, 17924, 20486, 20487, 20488, 20489, 20490, 20491, 20492, 20493, 20494, 20495, 20496, 20497, 20498, 20499, 20500, 20501, 20502, 20503, 20504, 20505, 20506, 20507, 20508, 20509, 20510, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20518, 20519, 20520, 20521, 20522, 20523, 20524], key=None, load=1000)\n",
      "SortedSet([',', ':', '@', 'Subject:', 'abominate', 'acrylate', 'alexander', 'almighty', 'annette', 'auxiliary', 'ballard', 'bam', 'banks', 'befog', 'bookcase', 'byroad', 'cable', 'cambric', 'canadian', 'canopy', 'charlie', 'cheer', 'china', 'cloister', 'clubroom', 'coffey', 'condition', 'contiguous', 'dabble', 'daphne', 'decadent', 'depressive', 'deride', 'desolate', 'diagnostician', 'elapse', 'else', 'emphysematous', 'ferret', 'free', 'giblet', 'gnaw', 'iturean', 'leadsman', 'lie', 'ligament', 'mania', 'oligarchy', 'ornately', 'quake', 'rdd', 're', 'seductive', 'segovia', 'sequestration', 'servomechanism', 'shut', 'synaptic', 'tetrachloride', 'the', 'trauma', 'tv', 'welsh', 'woodland', 'woodyard', 'yaqui'], key=None, load=1000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(RAW_DATASET.spam_emails[10].codes)\n",
    "print(RAW_DATASET.spam_emails[10].words())\n",
    "print(RAW_DATASET.spam_emails[10].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the preprocessing of the dataset *featurization*. The machine learning algorithm will interact with the *featurized* emails (the set of numbers and the 0/1 label), rather than the raw emails themselves.\n",
    "\n",
    "Featurization is an important part of data preparation. For instance, we saw previously in the linear regression notebooks that it was very helpful to normalize the mean and variance of continuous valued variables. Other featurization techniques are to lowercase words, to normalize whitespace. Sometimes *stemming* is done: this tries to normalize a word like \"robots\" to \"robot\", removing the \"s\". The \"stem\" is the base word. This is done because often the plethora of minor variants of words can be confusing to ML algorithms.\n",
    "\n",
    "It is not uncommon to throw away word order and word counts. This representation of text is called the *bag of words model*. Obviously a lot of information is lost with this representation. For some tasks like document retrieval based on keyword matching, the bag of words model can still be useful. For tasks like spam/not-spam bag of words performs well.\n",
    "\n",
    "For tasks which need deeper *semantic* understanding of a document (understanding what it means), we would want to use techniques which can exploit the information contained in the word ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Probabilities\n",
    "\n",
    "To detect which emails are spam and which aren't, we will use the observation that some words are more probable to appear in a spam email rather than in a non-spam email. For instance, I suspect that \"offer\" is more probable to appear in a spam email than a non-spam email. In notation:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    ">\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\\\]\n",
    "\n",
    "Now, what I really want to know is what is the probability that an email is spam if it contains the word \"offer\". That is, I want to calculate:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "\\\\]\n",
    "\n",
    "To do so, I will use *Bayes' Rule*:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\wedge \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "    \\cdot\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "It is frequently convenient to consider the *odds* that something is true, rather than the probability. If the probability of $X$ is $p$, then the *odds* of $X$ are $\\frac{p}{1-p}$. For instance, a probability of $0.66$ corresponds to an odds of $2$, sometimes written $2:1$.\n",
    "\n",
    "To calculate the odds that an email is spam if it has the word offer in it, first apply Bayes' Rule again to the probability that the email is not spam:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "    \\cdot\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Last, let's compute the odds:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Alright! Let's do this with code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham_odds': 0.4326241134751773, 'spam_odds': 2.3114754098360657}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_probabilities = RAW_DATASET.feature_probabilities()\n",
    "feature_probabilities.code_given_class_prob(\n",
    "    code = RAW_DATASET.word_encoding_dictionary.word_to_code('offer')\n",
    ").to_odds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this shows is that the odds that an email is spam are $2.3$ times greater if we know that it contains the word \"offer.\"\n",
    "\n",
    "To calculate the odds, we are using the counts observed in the dataset. We call this the *empirical* odds: empirical means \"known from experience or observation.\" Likewise, an *empirical* probability is one calculated using observed data.\n",
    "\n",
    "When there isn't very much data, an empirical quantity will be suspect. See below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts | {'ham_count': 0, 'spam_count': 1}\n",
      "Probs | {'ham_prob': 0.0, 'spam_prob': 1.0}\n",
      "Odds | {'ham_odds': 0.0, 'spam_odds': inf}\n"
     ]
    }
   ],
   "source": [
    "code = RAW_DATASET.word_encoding_dictionary.word_to_code('bacterial')\n",
    "\n",
    "print(f\"Counts | {feature_probabilities.code_counts[code]}\")\n",
    "print(f\"Probs | {feature_probabilities.code_given_class_prob(code)}\")\n",
    "print(f\"Odds | {feature_probabilities.code_given_class_prob(code).to_odds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, only one email had the word \"bacterial\" in it. It was a spam email. Therefore, the empirical probability:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{BACTERIAL} = 1} = 1.0\n",
    "\\\\]\n",
    "\n",
    "Here I'm trying to make clear that this probability is an *estimate* of the *true* probability using the empirical probability. Nobody thinks that the presence of the word \"bacteria\" guarantees an email is spam. In a case like this where the *reach* of a feature is only one example, the empirical probability can only be either $0.0$ or $1.0$. Both examples are completely extreme.\n",
    "\n",
    "Even though the empirical probability to converge to the true probability with more observations, the empirical probability may be very wrong when the sample size is low.\n",
    "\n",
    "How do we deal with this problem? There is more than one way. Let's adopt the simplest: let's throw away all features with a reach of less than twenty examples.\n",
    "\n",
    "To verify that the remaining features seem to be good, let's look at the top indicators that an email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077 | 2004 | reach: 122 | odds: 121.00:1\n",
      "5969 | microsoft | reach: 109 | odds: 8.91:1\n",
      "3104 | investment | reach: 107 | odds: 8.73:1\n",
      "3522 | results | reach: 116 | odds: 5.44:1\n",
      "370 | v | reach: 160 | odds: 5.15:1\n",
      "3951 | million | reach: 117 | odds: 4.85:1\n",
      "680 | stop | reach: 178 | odds: 4.74:1\n",
      "3900 | software | reach: 123 | odds: 4.59:1\n",
      "5621 | 80 | reach: 127 | odds: 4.52:1\n",
      "4002 | dollars | reach: 139 | odds: 4.35:1\n",
      "4611 | remove | reach: 138 | odds: 3.93:1\n",
      "3462 | stock | reach: 106 | odds: 3.82:1\n",
      "4795 | removed | reach: 105 | odds: 3.77:1\n",
      "2772 | money | reach: 237 | odds: 3.74:1\n",
      "2737 | world | reach: 158 | odds: 3.65:1\n",
      "2512 | save | reach: 160 | odds: 3.57:1\n",
      "2518 | http | reach: 610 | odds: 3.52:1\n",
      "570 | quality | reach: 130 | odds: 3.48:1\n",
      "4517 | canada | reach: 102 | odds: 3.43:1\n",
      "3347 | low | reach: 137 | odds: 3.42:1\n"
     ]
    }
   ],
   "source": [
    "filtered_feature_probabilities = RAW_DATASET.feature_probabilities().filter(reach_limit = 100)\n",
    "\n",
    "def top_features(fps, limit = 20):\n",
    "    count_items = list(fps.code_counts.items())\n",
    "    odds_items = list(map(\n",
    "        lambda pair: (pair[0], pair[1], pair[1].to_odds()),\n",
    "        count_items\n",
    "    ))\n",
    "    odds_items.sort(key = lambda triple: -triple[2].spam_odds)\n",
    "    return odds_items[:limit]\n",
    "\n",
    "for (code, counts, odds) in top_features(filtered_feature_probabilities):\n",
    "    word = RAW_DATASET.word_encoding_dictionary.code_to_word(code)\n",
    "    print(f\"{code} | {word} | reach: {counts.total_count()} | odds: {odds.spam_odds:0.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That list looks okay. It is a little bizarre to see 2004 up there. Let's move on for now.\n",
    "\n",
    "We want to use more than just a single word to characterize whether an email is spam. For instance, I want:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "Now, it is possible to count how many emails have *both* the words \"limited\" and \"offer.\" We could then count how many of those emails are spam. From these two counts we could calculate the empirical probability\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "However, we're just going to go back to our old problem. There may well not be enough emails that feature both words to estimate this probability properly. Even fewer examples will contain the three words \"offer\", \"limited\", and \"investment\". And our ultimate goal is try to estimate:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{all the words in the email}}\n",
    "\\\\]\n",
    "\n",
    "Since each new email likely represents a unique bag of words, there is almost no chance we've ever seen an email exactly like this. And even if we've seen one, that's not enough samples to reliably estimate this probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "\n",
    "We want to avoid ever conditioning on more than one feature, because when we condition on pairs of features, the number of examples with both those features will be far smaller than the number of examples with one or the other.\n",
    "\n",
    "Let's consider the words \"investment\" and \"quality\". From the above table, we have:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\eprob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1} &= \\frac{8.73}{8.73 + 1.0} = 0.89\\\\\n",
    "\\eprob{\\text{SPAM} = 1\\condbar \\text{QUALITY} = 1} &= \\frac{3.48}{3.48 + 1.0} = 0.77\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Here I have used the formula for converting odds back to probabilities. Because the reach of the \"investment\" and \"quality\" features is high, these estimates are probably pretty good. However, we want:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "\\\\]\n",
    "\n",
    "And we know that the empirical probability is likely a poor estimate of the true probability because we expect the reach of the pair of features together to be low.\n",
    "\n",
    "Let's try anyway and see where we get. Let's apply Bayes' rule as before:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "The denominator may be difficult to estimate because it involves the conjunction of the two features. But we can get rid of this if we use the odds like before:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Now, wouldn't it beautiful if:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "If this were true, it would say we could calculate the combined effect of having both \"investment\" and \"quality\" in an email by multiplying the two effects of having (1) \"investment\" and (2) \"quality\" in an email. Since we have good estimates of those individual odds ratio, we'll have a good estimate of the combined effect.\n",
    "\n",
    "When *would* this be true? Well, consider:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\\n",
    "=\n",
    "\\\\\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "\\\\]\n",
    "\n",
    "What did I just do here? Well: I just applied Bayes' rule. So this shows that we'll have our desired \"compounding\" of effects if:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "This property is called *conditional independence*. We say that the presence of the word \"quality\" is conditionally independent from the presence of the word \"investment\", *given* that we know the email to be spam.\n",
    "\n",
    "Let me show that the presence of \"quality\" and \"investment\" are not *unconditionally* independent. That is:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{INVESTMENT} = 1}\n",
    "\\ne\n",
    "\\prob{\\text{QUALITY} = 1}\n",
    "\\\\]\n",
    "\n",
    "Here's why this isn't true in general. The presence of the word \"investment\" suggests that the email is spam. And, if the email is spam, then it is more likely to contain the word \"quality\" than the average email. That means that the presence of the word \"investment\" makes the presence of the word \"quality\" more likely. Which is to say: the presence of \"investment\" and the presence of \"quality\" are not independent of each other.\n",
    "\n",
    "However, what if I already know that an email is spam? Normally, the presence of the word \"investment\" would indicate an email is spam, but I already know that. Therefore the presence of the word \"investment\" doesn't indicate the word \"quality\" is any more likely to be present through its indication that an email is spam. When we are conditioning on both $\\text{SPAM} = 1$ and $\\text{INVESTMENT} = 1$, the second piece of information loses its value in informing us about $\\text{SPAM}$, since we already know the value of that variable.\n",
    "\n",
    "The question then becomes: does the presence of the word investment change the probability of \"quality\" appearing for *any other* reason? Now, it may be possible that the words \"quality\" and \"investment\" often appear in the same spam emails because \"investment\" frequently appears as part of the compound phrase \"a quality investment\". If that were true, it may be that:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    ">\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "On the other hand, considering another pair of words, it may be that \"baldness\" is less likely given the presence of the word \"investment\" in spam emails. That might be because a spam email either pitches an investment or a baldness cure, but not typically both. In that case, the presence of \"investment\" might *inhibit* \"baldness.\" If this is true:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "<\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that, independent of their effect at hinting at whether an email is spam, a word like \"investment\" may (1) indicate the presence of \"quality\" or (2) indicate the absence of \"baldness.\"\n",
    "\n",
    "However, let's just pretend like that didn't happen. Let's just assume:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\\\\\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "We know this probably isn't true, but let's just pretend. The advantage is that we have pretty good estimates on quantities like $\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}$. And doing so let's us combine them in a simple (if somewhat unjustified) way:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "More generally, consider email contains the words $W_{i_1}, \\ldots, W_{i_k}$. I have used $i_1,\\ldots,i_k$ to represent that these are a subset of $k$ words in the set of all words. If there are $\\card{W}$ words, then the indices range over $1,\\ldots,\\card{W}$, but unless the email contains all words $k\\ne\\card{W}$.\n",
    "\n",
    "Anyway, if the email contains these words, then:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W_{i_1} = 1, \\ldots, W_{i_k} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_1} = 1, \\ldots, W_{i_k} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Okay! Let's try this out and see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.01 | Recall 0.22\n",
      "False Positive Rate 0.02 | Recall 0.34\n",
      "False Positive Rate 0.04 | Recall 0.52\n",
      "False Positive Rate 0.08 | Recall 0.75\n",
      "False Positive Rate 0.16 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    RAW_DATASET.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = False\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(RAW_DATASET, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *false positive rate* is the percentage of ham emails that were marked as spam. *Recall* is the percentage of percentage of spam emails that were identified as spam. Recall is the same as the *true positive rate*. Obviously the ideal is to have a false positive rate of zero and a recall of one.\n",
    "\n",
    "See that `use_negative_features = False`? Right now we've only been using words that were observed: words whose presence indicates spam or not spam.\n",
    "\n",
    "Another question is what about the *absence* of words? What if all spam emails contain a word? If it is absent, then we know this is a ham email. But our calculation isn't using that kind of information. The way we've written it, it's as if we know that some words are present, but *don't know* whether the other words are *absent*. So let's rewrite slightly. Assume that $w_i = 1$ when the word $W_i$ is present, and $w_i = 0$ otherwise. Then:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Let's see if the use of these features can help our model predict spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.01 | Recall 0.64\n",
      "False Positive Rate 0.02 | Recall 0.75\n",
      "False Positive Rate 0.04 | Recall 0.87\n",
      "False Positive Rate 0.08 | Recall 0.95\n",
      "False Positive Rate 0.16 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    RAW_DATASET.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = True\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(RAW_DATASET, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's way better! However, the way we are measuring performance is a little too leniant. We are supposed to train a model that predicts whether future emails are ham/spam, but we're measuring performance on the *training set*. This is often problematic because sometimes models will just \"memorize\" the training dataset in a way that doesn't lead to any future good performance.\n",
    "\n",
    "For instance, say our model was able to record an exact map from a bag of words to a label of ham or spam. Then, since every email in the training set probably has a unique bag of words, the model would be able to just record an exact mapping of email to label. But when we go to evaluate new emails, new emails won't match any of those bags of words. Thus there would be no ability to predict labels for future emails.\n",
    "\n",
    "To make sure our model *generalizes* well, it is common to split our data into two parts: the *training set* and the *test set*. The training set is fed to the machine learning algorithm, and then we use the test set to measure performance of the learned model. Since the ML algorithm never has seen the test set before, this should be a fair test of its ability to detect spam.\n",
    "\n",
    "Let's train on 80% of the data, and leave 20% for testing. There is a conflict of interest when picking these proportions. The more data you train on, the better your model will be. But the more data in your testing set, the more accurate your estimate on how the model will generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number of emails: 5172\n",
      "number of training emails: 4181\n",
      "number of test emails: 991\n",
      "False Positive Rate 0.01 | Recall 0.69\n",
      "False Positive Rate 0.02 | Recall 0.75\n",
      "False Positive Rate 0.04 | Recall 0.82\n",
      "False Positive Rate 0.08 | Recall 0.91\n",
      "False Positive Rate 0.16 | Recall 0.98\n"
     ]
    }
   ],
   "source": [
    "(training_set, test_set) = RAW_DATASET.split(ratio = 0.80)\n",
    "\n",
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "print(f\"total_number of emails: {len(RAW_DATASET.ham_emails) + len(RAW_DATASET.spam_emails)}\")\n",
    "print(f\"number of training emails: {len(training_set.ham_emails) + len(training_set.spam_emails)}\")\n",
    "print(f\"number of test emails: {len(test_set.ham_emails) + len(test_set.spam_emails)}\")\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    training_set.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = True\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(test_set, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Explain why overfitting is not a problem for this model.\n",
    "\n",
    "**TODO**: Explain PGM.\n",
    "\n",
    "**TODO**: Show that $\\prob{C \\condbar w_i}$ is inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import examples.pgm_diagram_example\n",
    "\n",
    "examples.pgm_diagram_example.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
